<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-medium.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-small.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="机器学习," />










<meta name="description" content="本文仅为个人笔记，错误之处敬请包涵。                                                         —— David 这篇介绍不涉及任何公式推导，仅提供一些思路以及相应的资料，感兴趣的可以自行查找资料学习。  书籍推荐理论类： 机器学习，周志华； 统计学习方法，李航； 深度学习，Ian goodfellow; 实践类： 机器学习实战，peter">
<meta name="keywords" content="机器学习">
<meta property="og:type" content="article">
<meta property="og:title" content="Machine learning">
<meta property="og:url" content="hellodavid.top/2018/08/26/machine-learning/index.html">
<meta property="og:site_name" content="HelloDavid">
<meta property="og:description" content="本文仅为个人笔记，错误之处敬请包涵。                                                         —— David 这篇介绍不涉及任何公式推导，仅提供一些思路以及相应的资料，感兴趣的可以自行查找资料学习。  书籍推荐理论类： 机器学习，周志华； 统计学习方法，李航； 深度学习，Ian goodfellow; 实践类： 机器学习实战，peter">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2018-08-26T08:31:29.733Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Machine learning">
<meta name="twitter:description" content="本文仅为个人笔记，错误之处敬请包涵。                                                         —— David 这篇介绍不涉及任何公式推导，仅提供一些思路以及相应的资料，感兴趣的可以自行查找资料学习。  书籍推荐理论类： 机器学习，周志华； 统计学习方法，李航； 深度学习，Ian goodfellow; 实践类： 机器学习实战，peter">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="hellodavid.top/2018/08/26/machine-learning/"/>





  <title>Machine learning | HelloDavid</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">HelloDavid</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="hellodavid.top/2018/08/26/machine-learning/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="David">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HelloDavid">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Machine learning</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-26T14:43:27+08:00">
                2018-08-26
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i>
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>
            </span>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <blockquote>
<p>本文仅为个人笔记，错误之处敬请包涵。                                                         —— David</p>
<p>这篇介绍不涉及任何公式推导，仅提供一些思路以及相应的资料，感兴趣的可以自行查找资料学习。</p>
</blockquote>
<h2 id="书籍推荐"><a href="#书籍推荐" class="headerlink" title="书籍推荐"></a>书籍推荐</h2><p>理论类：</p>
<p>机器学习，周志华；</p>
<p>统计学习方法，李航；</p>
<p>深度学习，Ian goodfellow;</p>
<p>实践类：</p>
<p>机器学习实战，peter harrington；</p>
<p>python机器学习及实践，范淼；</p>
<p>休闲类：</p>
<p>数学之美，吴军；</p>
<p>##博客推荐：</p>
<p>刘建平的博客：<a href="https://www.cnblogs.com/pinard/" target="_blank" rel="noopener">https://www.cnblogs.com/pinard/</a></p>
<p>peghoty的博客：<a href="https://blog.csdn.net/itplus" target="_blank" rel="noopener">https://blog.csdn.net/itplus</a></p>
<p>poll的笔记：<a href="http://www.cnblogs.com/maybe2030/" target="_blank" rel="noopener">http://www.cnblogs.com/maybe2030/</a></p>
<h2 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h2><p>监督学习是指对<strong>带标签</strong>的数据进行模型学习。</p>
<h3 id="回归"><a href="#回归" class="headerlink" title="回归"></a>回归</h3><p>回归任务常见的是线性回归linear regression. </p>
<p>注意回归和分类任务的区别，回归的标签值是连续值，而分类的标签值是离散值。</p>
<p>通常我们还会遇到逻辑回归logistic regression, 注意，逻辑回归是用于分类的！</p>
<p>逻辑回归LR是机器学习中非常基础的算法，因此非常重要。</p>
<p>知识点：交叉熵损失函数，极大似然估计。</p>
<p>相关资料：</p>
<p>poll的博客：<a href="http://www.cnblogs.com/maybe2030/p/5494931.html" target="_blank" rel="noopener">www.cnblogs.com/maybe2030/p/5494931.html</a> </p>
<p>逻辑回归：<a href="https://www.cnblogs.com/Belter/p/6128644.html" target="_blank" rel="noopener">https://www.cnblogs.com/Belter/p/6128644.html</a></p>
<p>逻辑回归推导：<a href="http://blog.csdn.net/pakko/article/details/37878837" target="_blank" rel="noopener">http://blog.csdn.net/pakko/article/details/37878837</a></p>
<p>极大似然估计：<a href="http://blog.csdn.net/star_liux/article/details/39666737" target="_blank" rel="noopener">http://blog.csdn.net/star_liux/article/details/39666737</a></p>
<h3 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h3><p>通俗来讲，它是一种二类分类模型，其基本模型定义为特征空间上的间隔最大的线性分类器，其学习策略便是间隔最大化，最终可转化为一个凸二次规划问题的求解。</p>
<p>知识点：函数间隔，几何间隔，对偶问题，核函数，软间隔，hinge loss</p>
<p>相关资料：</p>
<p>周志华，机器学习：SVM</p>
<p>图形解释，知乎：<a href="https://www.zhihu.com/question/21094489" target="_blank" rel="noopener">https://www.zhihu.com/question/21094489</a></p>
<p>支持向量机通俗解释，CSDN: <a href="http://blog.csdn.net/v_july_v/article/details/7624837" target="_blank" rel="noopener">http://blog.csdn.net/v_july_v/article/details/7624837</a></p>
<p>支持向量机通俗导论，july: <a href="https://blog.csdn.net/v_july_v/article/details/7624837" target="_blank" rel="noopener">https://blog.csdn.net/v_july_v/article/details/7624837</a></p>
<h3 id="KNN"><a href="#KNN" class="headerlink" title="KNN"></a>KNN</h3><p>给定测试样本，基于某种距离度量找出训练集中与其最靠近的k个训练样本，然后基于这k个邻居的信息来进行预测。K=1时，为最近邻算法。 </p>
<p>知识点：k值的选择，距离度量，kd树定义及构建</p>
<p>相关资料：</p>
<p>李航，统计学习，第三章 </p>
<h3 id="因子分解机"><a href="#因子分解机" class="headerlink" title="因子分解机"></a>因子分解机</h3><p>因子分解机主要是考虑了特征之间的关联。</p>
<p>FM主要是为了解决数据稀疏的情况下，（而SVM无法解决稀疏问题），特征怎样组合的问题。</p>
<p>知识点：计算复杂度的推导，梯度计算</p>
<p>相关资料：</p>
<p>FM算法详解：<a href="https://blog.csdn.net/bitcarmanlee/article/details/52143909" target="_blank" rel="noopener">https://blog.csdn.net/bitcarmanlee/article/details/52143909</a></p>
<p>FM计算：<a href="https://blog.csdn.net/shenxiaolu1984/article/details/78740481" target="_blank" rel="noopener">https://blog.csdn.net/shenxiaolu1984/article/details/78740481</a></p>
<p>###HMM隐马尔可夫模型</p>
<p>隐马模型相对包含内容较多，需要考虑三个基本问题：评估问题，解码问题，和学习问题。</p>
<p>为了更好的理解隐马模型，可以通过<a href="http://www.cnblogs.com/skyme/p/4651331.html" target="_blank" rel="noopener">http://www.cnblogs.com/skyme/p/4651331.html</a> 这篇文章入门，对隐马模型的隐含状态，可见状态，转换概率等概念有较为清楚的理解。</p>
<p>知识点：评估问题，前向后向算法；解码问题，维特比算法；学习问题，EM算法</p>
<p>相关资料：</p>
<p>Cnblog，骰子说明隐马模型：<a href="http://www.cnblogs.com/skyme/p/4651331.html" target="_blank" rel="noopener">http://www.cnblogs.com/skyme/p/4651331.html</a></p>
<p>维特比算法说明,及python实现：<a href="https://www.cnblogs.com/ylHe/p/6912017.html" target="_blank" rel="noopener">https://www.cnblogs.com/ylHe/p/6912017.html</a></p>
<p>数学之美，第5章，隐马模型，BW算法</p>
<h2 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h2><p>无监督学习是对<strong>无标签</strong>的数据进行模型学习。</p>
<h3 id="聚类"><a href="#聚类" class="headerlink" title="聚类"></a>聚类</h3><p>最基本的算法是K-means, 通过不断的迭代得到最终结果。</p>
<p>知识点：K-means的步骤，k值的确定（注意，这里的k和knn中的k概念不同），如何确定k个初始类簇中心点；</p>
<h3 id="频繁项集和关联分析"><a href="#频繁项集和关联分析" class="headerlink" title="频繁项集和关联分析"></a>频繁项集和关联分析</h3><p>频繁项集主要是指经常出现在一块的物品的集合，关联分析是指从大规模数据中寻找物品间的隐含关系。在寻找频繁项集的过程中，主要有两种算法，Apriori以及FP-growth.</p>
<p>知识点：清楚相关概念：包括项，项集，事务，关联分析，频繁项集，关联规则，支持度，置信度；熟悉Apriori，和FP-growth算法</p>
<p>相关资料：</p>
<p>FP-tree算法的实现：<a href="https://www.cnblogs.com/zhangchaoyang/articles/2198946.html" target="_blank" rel="noopener">https://www.cnblogs.com/zhangchaoyang/articles/2198946.html</a> </p>
<h3 id="序列模式"><a href="#序列模式" class="headerlink" title="序列模式"></a>序列模式</h3><p>序列模式属于频繁模式的进阶，频繁模式是挖掘事务中的频繁项，序列模式是挖掘频繁的子序列。可以认为，事务是项的无序集合，序列是事务的有序集合。因此，可以和频繁项集对比学习。</p>
<p>知识点：序列的概念，相关算法实现：GSP, SPADE, PrefixSpan,…</p>
<p>相关资料：</p>
<p>数据挖掘关联分析：<a href="https://www.cnblogs.com/beaver-sea/p/4743167.html" target="_blank" rel="noopener">https://www.cnblogs.com/beaver-sea/p/4743167.html</a></p>
<p>序列模式，GSP：<a href="http://blog.csdn.net/rongyongfeikai2/article/details/40478335" target="_blank" rel="noopener">http://blog.csdn.net/rongyongfeikai2/article/details/40478335</a></p>
<p>刘建平，PrefixSpan: <a href="https://www.cnblogs.com/pinard/p/6323182.html" target="_blank" rel="noopener">https://www.cnblogs.com/pinard/p/6323182.html</a></p>
<h2 id="基本分析"><a href="#基本分析" class="headerlink" title="基本分析"></a>基本分析</h2><p>一些在机器学习中常用到的基本概念。</p>
<h3 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h3><p>梯度下降是机器学习中必然掌握的核心概念，需要能够继续推导。为了更好的理解梯度下降，建议从梯度的概念着手。</p>
<p>知识点：梯度下降的概念，批量梯度下降，随机梯度下降，小批量梯度下降（最常用），反向传播</p>
<p>相关资料：</p>
<p>Poll的笔记，梯度下降法的三种形式BGD、SGD以及MBGD：<a href="https://www.cnblogs.com/maybe2030/p/5089753.html" target="_blank" rel="noopener">https://www.cnblogs.com/maybe2030/p/5089753.html</a></p>
<p>反向传播，代入数值具体计算：<a href="https://www.cnblogs.com/charlotte77/p/5629865.html" target="_blank" rel="noopener">https://www.cnblogs.com/charlotte77/p/5629865.html</a></p>
<p>SGD, BGD, MBGD的比较：<a href="https://blog.csdn.net/tsyccnh/article/details/76136771" target="_blank" rel="noopener">https://blog.csdn.net/tsyccnh/article/details/76136771</a></p>
<h3 id="超参数"><a href="#超参数" class="headerlink" title="超参数"></a>超参数</h3><p>所谓的模型配置，一般统称为模型的超参数（Hyperparameters），比如KNN算法中的K值，SVM中不同的核函数（Kernal）等。多数情况下，超参数等选择是无限的。在有限的时间内，除了可以验证人工预设几种超参数组合以外，也可以通过启发式的搜索方法对超参数组合进行调优。称这种启发式的超参数搜索方法为网格搜索。 </p>
<p>实战中调参即指对超参数的调参。</p>
<h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>损失函数用来评价模型的预测值和真实值不一样的程度，损失函数越小，通常模型的性能越好。</p>
<p>把最大化或者最小化的函数称为目标函数，把需要最小化的函数称为代价函数或者损失函数，因为我们的优化是最小化代价或者损失。</p>
<p>损失函数分为经验风险损失函数和结构风险损失函数。简单来说，结构风险损失函数就是在经验风险损失函数的基础上加上了正则项。</p>
<p>常见损失函数包括：绝对值损失函数，对数损失函数（通常用于分类），平方损失函数（通常用于回归）…</p>
<p>相关资料：</p>
<p>交叉熵：<a href="http://blog.csdn.net/sinat_29819401/article/details/58716834" target="_blank" rel="noopener">http://blog.csdn.net/sinat_29819401/article/details/58716834</a></p>
<p>常见的几种损失函数：<a href="https://www.cnblogs.com/hejunlin1992/p/8158933.html" target="_blank" rel="noopener">https://www.cnblogs.com/hejunlin1992/p/8158933.html</a></p>
<p>知乎，目标函数，损失函数和代价函数的区别：<a href="https://www.zhihu.com/question/52398145" target="_blank" rel="noopener">https://www.zhihu.com/question/52398145</a></p>
<h3 id="算法常用指标"><a href="#算法常用指标" class="headerlink" title="算法常用指标"></a>算法常用指标</h3><p>分类常见指标包括AUC，ROC，召回率，准确率..</p>
<p>回归常见指标包括RMSE…</p>
<p>相关资料：</p>
<p>poll的笔记：<a href="http://www.cnblogs.com/maybe2030/p/5375175.html" target="_blank" rel="noopener">www.cnblogs.com/maybe2030/p/5375175.html</a> </p>
<p>AUC，ROC：<a href="https://www.jianshu.com/p/c61ae11cc5f6" target="_blank" rel="noopener">https://www.jianshu.com/p/c61ae11cc5f6</a> </p>
<h3 id="特征选择和特征抽取"><a href="#特征选择和特征抽取" class="headerlink" title="特征选择和特征抽取"></a>特征选择和特征抽取</h3><p>在机器学习中特征是非常重要的，经常需要进行特征工程，因此特征选择和特征抽取相当关键。</p>
<p>特征抽取（Feature Extraction）:Creatting a subset of new features by combinations of the exsiting features.也就是说，特征抽取后的新特征是原来特征的一个映射。</p>
<p>特征选择（Feature Selection）:choosing a subset of all the features(the ones more informative)。也就是说，特征选择后的特征是原来特征的一个子集。</p>
<p>特征抽取算法包括PCA，LDA…</p>
<p>特征选择算法包括三类：Filter, Wrapper, and Embedded</p>
<p>知识点：特征选择和特征抽取的意义，PCA,  SVD, …</p>
<p>相关资料：</p>
<p>csdn博客：<a href="http://blog.csdn.net/shenxiaoming77/article/details/50555054" target="_blank" rel="noopener">http://blog.csdn.net/shenxiaoming77/article/details/50555054</a></p>
<p>周志华，机器学习，11章：特征选择和稀疏学习</p>
<p>伯乐在线，主成分分析原理详解：<a href="http://blog.jobbole.com/109015/" target="_blank" rel="noopener">http://blog.jobbole.com/109015/</a></p>
<h3 id="连续值，异常值，缺失值处理"><a href="#连续值，异常值，缺失值处理" class="headerlink" title="连续值，异常值，缺失值处理"></a>连续值，异常值，缺失值处理</h3><p>知识点：连续值转换为离散值，异常值检测，缺失值填充</p>
<h3 id="L1和L2正则化"><a href="#L1和L2正则化" class="headerlink" title="L1和L2正则化"></a>L1和L2正则化</h3><p>知识点：了解正则化的目标，L1和L2正则的作用，等值线图的含义</p>
<p>相关资料：</p>
<p>博客：<a href="http://blog.csdn.net/zouxy09/article/details/24971995" target="_blank" rel="noopener">http://blog.csdn.net/zouxy09/article/details/24971995</a></p>
<p>L2正则化导致参数较小：<a href="https://blog.csdn.net/jinping_shi/article/details/52433975" target="_blank" rel="noopener">https://blog.csdn.net/jinping_shi/article/details/52433975</a></p>
<p>等值线图形的解释：<a href="https://blog.csdn.net/weixin_39845112/article/details/80114918" target="_blank" rel="noopener">https://blog.csdn.net/weixin_39845112/article/details/80114918</a></p>
<h3 id="过拟合"><a href="#过拟合" class="headerlink" title="过拟合"></a>过拟合</h3><p>过拟合的一些解决方法：</p>
<ul>
<li>增加样本数据量；</li>
<li>正则化，L1和L2正则；</li>
<li>神经网络中，dropout方法。就是每层网络的训练，随机的让一半神经元不工作。达到防止过拟合的目的。</li>
<li>决策树中可以用剪枝操作</li>
<li>提升方法：early stopping，当训练集合的误差降低，但是验证集合的误差增加时，则停止训练，同时返回具有最小验证集合误差的神经网络；</li>
<li>Data augmentation：创建假数据并增加到训练集中</li>
</ul>
<h3 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h3><p>训练集training set：用以建立模型，是用来训练模型或确定模型参数的</p>
<p>测试集testing set: 用来评估模型对未知样本进行预测时的精确度，即泛化能力</p>
<p>验证集validation set: 验证集是原始训练集的子集，用来做模型选择</p>
<h2 id="集成学习"><a href="#集成学习" class="headerlink" title="集成学习"></a>集成学习</h2><p>集成学习在机器学习中有非常重要的地位，因此需要深入的研究。集成学习重要分为三种，Boosting, Bagging 和Stacking。</p>
<p>Boosting包括了GBDT, XGBoost, AdaBoost…</p>
<p>Bagging包含了随机森林</p>
<h3 id="GBDT"><a href="#GBDT" class="headerlink" title="GBDT"></a>GBDT</h3><p>GBDT中的树都是回归树，不是分类树。</p>
<p>每一轮弱学习器的目标是使预测值接近残差， 强学习器的作用是累加前面所有的弱学习器结果，使预测值接近实际值。</p>
<p>残差是上一轮强学习器的预测结果和实际值的差值或者用损失函数的负梯度方向表示。</p>
<p>Gradient Boosting 是GBDT的核心思想，它相比与 Boosting Tree 的主要改进在于: </p>
<p>Boosting Tree 对于每一轮基学习器，拟合的是当前模型与标签值的残差 ，</p>
<p>GBDT 对于每一轮基学习器，拟合的是当前模型与标签值的残差的负梯度。</p>
<p>知识点：CART回归树，负梯度，GBDT多分类，GBDT与XGBoost的区别</p>
<p>相关资料：</p>
<p>入门介绍：<a href="http://blog.csdn.net/w28971023/article/details/8240756" target="_blank" rel="noopener">http://blog.csdn.net/w28971023/article/details/8240756</a></p>
<p>刘建平：<a href="https://www.cnblogs.com/pinard/p/6140514.html" target="_blank" rel="noopener">https://www.cnblogs.com/pinard/p/6140514.html</a></p>
<p>集成学习总结：<a href="https://xijunlee.github.io/2017/06/03/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/" target="_blank" rel="noopener">https://xijunlee.github.io/2017/06/03/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/</a></p>
<p>GBDT和XGBoost比较：<a href="https://blog.csdn.net/panda_zjd/article/details/71577463" target="_blank" rel="noopener">https://blog.csdn.net/panda_zjd/article/details/71577463</a></p>
<p>面试题整理：<a href="https://blog.csdn.net/qq_28031525/article/details/70207918" target="_blank" rel="noopener">https://blog.csdn.net/qq_28031525/article/details/70207918</a></p>
<p>GBDT构建特征：<a href="https://blog.csdn.net/shine19930820/article/details/71713680#2-gbdt构建新的特征思想" target="_blank" rel="noopener">https://blog.csdn.net/shine19930820/article/details/71713680#2-gbdt构建新的特征思想</a></p>
<p>GBDT与Boosting Tree的区别：<a href="https://blog.csdn.net/Liangjun_Feng/article/details/80142724?spm=5176.11104323.5600004.1.444e717dXEDRaI" target="_blank" rel="noopener">https://blog.csdn.net/Liangjun_Feng/article/details/80142724?spm=5176.11104323.5600004.1.444e717dXEDRaI</a></p>
<h3 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h3><p>是对GBDT的一种改进，也是实战中常用的模型，因此需要加深理解，建议直接看陈天奇大神的论文，以及他的PPT介绍。</p>
<p>知识点：了解XGBoost模型中各个参数的含义</p>
<h3 id="Lightgbm"><a href="#Lightgbm" class="headerlink" title="Lightgbm"></a>Lightgbm</h3><p>是另一种常见的模型，由微软提出。</p>
<p>知识点：了解Lightgbm中各个参数的含义，了解lightgbm和xgboost的比较</p>
<h3 id="DART"><a href="#DART" class="headerlink" title="DART"></a>DART</h3><p>将drop out引入到boosting模型中的一种算法。解决over specilization的问题，即初始的第一棵树对整体方向起关键作用，而后续的树一直处于弥补残差的状态，并且只影响一小部分样本，这样后面的树对整体的贡献也在逐渐的弱化。 </p>
<p>相关资料：</p>
<p>Csdn: <a href="https://blog.csdn.net/Yongchun_Zhu/article/details/78745529" target="_blank" rel="noopener">https://blog.csdn.net/Yongchun_Zhu/article/details/78745529</a> </p>
<h3 id="AdaBoost"><a href="#AdaBoost" class="headerlink" title="AdaBoost"></a>AdaBoost</h3><p>adaboost算法的核心思想就是由分类效果较差的弱分类器逐步的强化成一个分类效果较好的强分类器。而强化的过程，就是逐步的改变样本权重，样本权重的高低，代表其在分类器训练过程中的重要程度。 </p>
<p>相关资料：</p>
<p>深度剖析adaboost: <a href="http://blog.csdn.net/autocyz/article/details/51305999" target="_blank" rel="noopener">http://blog.csdn.net/autocyz/article/details/51305999</a></p>
<p>一问读懂adaboost: <a href="http://www.xtecher.com/Xfeature/view?aid=8109" target="_blank" rel="noopener">www.xtecher.com/Xfeature/view?aid=8109</a></p>
<h3 id="随机森林和决策树"><a href="#随机森林和决策树" class="headerlink" title="随机森林和决策树"></a>随机森林和决策树</h3><p>决策树的关键是选择最优划分属性，了解三种划分属性的方式，如ID3, C4.5, GINI。</p>
<p>Random Forest（随机森林）是Bagging的扩展变体，它在以决策树为基学习器构建Bagging集成的基础上，进一步在决策树的训练过程中引入了随机特征选择，因此可以概括RF包括四个部分：</p>
<p>1、随机选择样本（放回抽样）；</p>
<p>2、构建决策树（CART树）；</p>
<p>3、随机选择特征；</p>
<p>4、随机森林投票（平均）。 </p>
<p>知识点：决策树划分属性的方式，剪枝，Bootstrapping，随机森林进行特征选择</p>
<p>相关资料：</p>
<p>周志华，机器学习；</p>
<p>CART回归树, 李航，第五章决策树；</p>
<p>随机森林，面试：<a href="https://blog.csdn.net/qq_28031525/article/details/70207918" target="_blank" rel="noopener">https://blog.csdn.net/qq_28031525/article/details/70207918</a></p>
<p>特征选择：<a href="https://blog.csdn.net/banbuduoyujian/article/details/60328474" target="_blank" rel="noopener">https://blog.csdn.net/banbuduoyujian/article/details/60328474</a></p>
<h3 id="stacking"><a href="#stacking" class="headerlink" title="stacking"></a>stacking</h3><p>在kaggle比赛中常用的一种算法，将训练好的所有基模型对整个训练集进行预测，第j个基模型对第i个训练样本的预测值将作为新的训练集中第i个样本的第j个特征值(预测值变成了特征值），最后基于新的训练集进行训练。 </p>
<p>相关资料：</p>
<p>从boosting到stacking: <a href="https://baijiahao.baidu.com/s?id=1576971033986792968&amp;wfr=spider&amp;for=pc" target="_blank" rel="noopener">https://baijiahao.baidu.com/s?id=1576971033986792968&amp;wfr=spider&amp;for=pc</a></p>
<p>csdn博客，集成学习总结：<a href="https://blog.csdn.net/willduan1/article/details/73618677" target="_blank" rel="noopener">https://blog.csdn.net/willduan1/article/details/73618677</a></p>
<p>stack图形说明：<a href="https://www.leiphone.com/news/201709/zYIOJqMzR0mJARzj.html" target="_blank" rel="noopener">https://www.leiphone.com/news/201709/zYIOJqMzR0mJARzj.html</a></p>
<p>Stacking, kaggle: <a href="https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard" target="_blank" rel="noopener">https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard</a></p>
<h2 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h2><h3 id="数据归一化"><a href="#数据归一化" class="headerlink" title="数据归一化"></a>数据归一化</h3><p>归一化的作用：</p>
<ul>
<li><p>归一化后加快了梯度下降求最优解的速度</p>
</li>
<li><p>归一化有可能提高精度</p>
</li>
</ul>
<p>中心化Zero-centered/Mean-substraction：</p>
<ul>
<li>指变量减去它的均值</li>
</ul>
<p>标准化Standardization/Normalization</p>
<ul>
<li>指变量减去均值后（中心化），再除以标准差；</li>
</ul>
<p>意义：数据中心化和标准化的作用的取消在回归分析中由于不同特征量纲不同或者数值相差较大所引起的误差。</p>
<p>注意：归一化和标准化都是线性变换。</p>
<p>相关资料：</p>
<p>归一化：<a href="http://www.cnblogs.com/LBSer/p/4440590.html" target="_blank" rel="noopener">http://www.cnblogs.com/LBSer/p/4440590.html</a> </p>
<h3 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h3><p>数据预处理，相当于深度学习中的数据归一化。</p>
<p>普通机器学习的归一化只针对输入层，而BN针对中间每一层输入进行归一化。</p>
<p>归一化的目的是使的数据的分布集中在激活函数的敏感区域（即中间区域）。</p>
<p>BN层就是对深度学习的中间层的输入数据进行归一化，解决在训练过程中，中间层数据分布发生改变的情况，使得每一层的分布相似，同时保留原来每层训练得到的特征分布（通过变换重构）。</p>
<p>相关资料：</p>
<p>Batch normalization 学习笔记：<a href="https://blog.csdn.net/hjimce/article/details/50866313" target="_blank" rel="noopener">https://blog.csdn.net/hjimce/article/details/50866313</a> </p>
<h3 id="白化-whitening"><a href="#白化-whitening" class="headerlink" title="白化 whitening"></a>白化 whitening</h3><p>白化就是深度学习里的PCA. 分为PCA白化和ZCA白化。</p>
<p>白化的目的是去除输入数据的冗余信息。假设训练数据是图像，由于图像中相邻像素之间具有很强的相关性，所以用于训练时输入是冗余的；</p>
<p><strong>白化的目的就是降低输入的冗余性</strong>。</p>
<p>白化和PCA的关系：</p>
<p>PCA如果不降维，而是仅仅使用PCA求出特征向量，然后把数据X映射到新的特征空间，这样的一个映射过程，其实就是满足了我们白化的第一个性质：除去特征之间的相关性。因此白化算法的实现过程，第一步操作就是PCA，求出新特征空间中X的新坐标，然后再对新的坐标进行方差归一化操作。</p>
<p>相关资料：</p>
<p>白化，hjimce: <a href="https://blog.csdn.net/hjimce/article/details/50864602" target="_blank" rel="noopener">https://blog.csdn.net/hjimce/article/details/50864602</a> </p>
<h3 id="分类不均衡问题"><a href="#分类不均衡问题" class="headerlink" title="分类不均衡问题"></a>分类不均衡问题</h3><p>分类不均衡问题是指：分类任务中不同类别的训练样例数目差别很大的情况。 </p>
<p><strong>对样例数目较多的类别进行欠抽样（undersampling)</strong>（1,2,3均是删去多数类样本的方法）：</p>
<ol>
<li><ol>
<li>随机欠采样：最简单的办法是从多数类中随机抽取样本从而减少多数类样本的数量，使数据达到平衡；</li>
<li>Edited Nearest Neighbor(ENN): 在多数类的样本中，如果该样本周围的K近邻样本都是少数类，则将该多数类样本删除；</li>
<li>Tomek Link Removal:如果有两个不同类别的样本，它们的最近邻都是对方，那么A,B就是Tomek link。我们要做的就是将所有Tomek link都删除掉，即将组成Tomek       link的两个样本，如果有一个属于多数类样本，就将该多数类样本删除掉。</li>
<li>代表性算法EasyEnsemble,利用集成学习机制，将该类别划分为若干个集合供不同学习器使用，对于每个学习器来说都是欠采样，但从全局来看却不会丢失重要信息。</li>
</ol>
</li>
</ol>
<p><strong>对样例数目较少的类别进行过抽样（oversampling)</strong>：</p>
<p>过抽样不是简单的对样本进行重复抽样，否则会招致严重的过拟合，过采样的代表算法是SMOTE,基本思想是对少数类样本进行分析并根据少数类样本人工合成新样本添加到数据集中。简单来说，人工合成的样本是每个少数类样本与其K近邻的连线上的点。</p>
<p><strong>再缩放（再平衡）技术</strong></p>
<p>即给少数类较多的权重，而给多数类更少的权重，使得少数类判别错误的损失大于多数类判别错误的损失，其中，缩放因子为类别样例数目的比值</p>
<p>相关资料：</p>
<p>SMOTE算法：<a href="https://blog.csdn.net/jiede1/article/details/70215477" target="_blank" rel="noopener">https://blog.csdn.net/jiede1/article/details/70215477</a></p>
<p>分类不均衡：<a href="https://blog.csdn.net/ly_ysys629/article/details/72846200" target="_blank" rel="noopener">https://blog.csdn.net/ly_ysys629/article/details/72846200</a></p>
<p>分类不均衡方法综述: <a href="http://lib.csdn.net/article/machinelearning/41294" target="_blank" rel="noopener">http://lib.csdn.net/article/machinelearning/41294</a></p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/机器学习/" rel="tag"># 机器学习</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/08/26/hello-world/" rel="next" title="Hello World">
                <i class="fa fa-chevron-left"></i> Hello World
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/08/26/Leetcode-Reverse Linked List/" rel="prev" title="Remove Duplicates from Sorted List">
                Remove Duplicates from Sorted List <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.jpg"
                alt="David" />
            
              <p class="site-author-name" itemprop="name">David</p>
              <p class="site-description motion-element" itemprop="description">From Zero to One</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#书籍推荐"><span class="nav-number">1.</span> <span class="nav-text">书籍推荐</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#监督学习"><span class="nav-number">2.</span> <span class="nav-text">监督学习</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#回归"><span class="nav-number">2.1.</span> <span class="nav-text">回归</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#SVM"><span class="nav-number">2.2.</span> <span class="nav-text">SVM</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#KNN"><span class="nav-number">2.3.</span> <span class="nav-text">KNN</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#因子分解机"><span class="nav-number">2.4.</span> <span class="nav-text">因子分解机</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#无监督学习"><span class="nav-number">3.</span> <span class="nav-text">无监督学习</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#聚类"><span class="nav-number">3.1.</span> <span class="nav-text">聚类</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#频繁项集和关联分析"><span class="nav-number">3.2.</span> <span class="nav-text">频繁项集和关联分析</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#序列模式"><span class="nav-number">3.3.</span> <span class="nav-text">序列模式</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#基本分析"><span class="nav-number">4.</span> <span class="nav-text">基本分析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#梯度下降"><span class="nav-number">4.1.</span> <span class="nav-text">梯度下降</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#超参数"><span class="nav-number">4.2.</span> <span class="nav-text">超参数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#损失函数"><span class="nav-number">4.3.</span> <span class="nav-text">损失函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#算法常用指标"><span class="nav-number">4.4.</span> <span class="nav-text">算法常用指标</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#特征选择和特征抽取"><span class="nav-number">4.5.</span> <span class="nav-text">特征选择和特征抽取</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#连续值，异常值，缺失值处理"><span class="nav-number">4.6.</span> <span class="nav-text">连续值，异常值，缺失值处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#L1和L2正则化"><span class="nav-number">4.7.</span> <span class="nav-text">L1和L2正则化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#过拟合"><span class="nav-number">4.8.</span> <span class="nav-text">过拟合</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#交叉验证"><span class="nav-number">4.9.</span> <span class="nav-text">交叉验证</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#集成学习"><span class="nav-number">5.</span> <span class="nav-text">集成学习</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#GBDT"><span class="nav-number">5.1.</span> <span class="nav-text">GBDT</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#XGBoost"><span class="nav-number">5.2.</span> <span class="nav-text">XGBoost</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Lightgbm"><span class="nav-number">5.3.</span> <span class="nav-text">Lightgbm</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#DART"><span class="nav-number">5.4.</span> <span class="nav-text">DART</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#AdaBoost"><span class="nav-number">5.5.</span> <span class="nav-text">AdaBoost</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#随机森林和决策树"><span class="nav-number">5.6.</span> <span class="nav-text">随机森林和决策树</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#stacking"><span class="nav-number">5.7.</span> <span class="nav-text">stacking</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#数据处理"><span class="nav-number">6.</span> <span class="nav-text">数据处理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#数据归一化"><span class="nav-number">6.1.</span> <span class="nav-text">数据归一化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Batch-Normalization"><span class="nav-number">6.2.</span> <span class="nav-text">Batch Normalization</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#白化-whitening"><span class="nav-number">6.3.</span> <span class="nav-text">白化 whitening</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#分类不均衡问题"><span class="nav-number">6.4.</span> <span class="nav-text">分类不均衡问题</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">David</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  


  

  

</body>
</html>
