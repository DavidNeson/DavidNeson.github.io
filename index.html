<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-medium.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-small.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="From Zero to One">
<meta property="og:type" content="website">
<meta property="og:title" content="HelloDavid">
<meta property="og:url" content="hellodavid.top/index.html">
<meta property="og:site_name" content="HelloDavid">
<meta property="og:description" content="From Zero to One">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="HelloDavid">
<meta name="twitter:description" content="From Zero to One">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="hellodavid.top/"/>





  <title>HelloDavid</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">HelloDavid</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="hellodavid.top/2018/09/11/linear and logistic learning/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="David">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/myavatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HelloDavid">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/11/linear and logistic learning/" itemprop="url">线性回归和逻辑回归的比较</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-09-11T17:56:10+08:00">
                2018-09-11
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h1><p><img src="/../typora-images/1536368052441.png" alt="1536368052441"></p>
<p>用一组变量的（特征）的线性组合，来建立与结果之间的关系。</p>
<p>模型表达：$y(x, w)=w_0+w_1x_1+…+w_nx_n$</p>
<h1 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h1><p>逻辑回归用于<strong>分类</strong>，而不是回归。</p>
<p>在线性回归模型中，输出一般是连续的， 对于每一个输入的x，都有一个对应的输出y。因此模型的定义域和值域都可以是无穷。</p>
<p>但是对于逻辑回归，输入可以是连续的[-∞, +∞]，但输出一般是离散的，通常只有两个值{0, 1}。</p>
<p>这两个值可以表示对样本的某种分类，高/低、患病/ 健康、阴性/阳性等，这就是最常见的二分类逻辑回归。因此，从整体上来说，通过逻辑回归模型，我们将在整个实数范围上的x映射到了有限个点上，这样就实现了对x的分类。因为每次拿过来一个x，经过逻辑回归分析，就可以将它归入某一类y中。</p>
<h1 id="逻辑回归与线性回归的关系"><a href="#逻辑回归与线性回归的关系" class="headerlink" title="逻辑回归与线性回归的关系"></a>逻辑回归与线性回归的关系</h1><p>可以认为逻辑回归的输入是线性回归的输出，将逻辑斯蒂函数（Sigmoid曲线）作用于线性回归的输出得到输出结果。</p>
<p>线性回归y = ax + b, 其中a和b是待求参数；</p>
<p>逻辑回归p = S(ax + b), 其中a和b是待求参数， S是逻辑斯蒂函数，然后根据p与1-p的大小确定输出的值，通常阈值取0.5，若p大于0.5则归为1这类。</p>
<p>具体的：</p>
<p>线性函数如下：</p>
<p><img src="/../typora-images/clip_image001-1536544529885.png" alt="img"></p>
<p>构造预测函数：</p>
<p><img src="/../typora-images/1536544616811.png" alt="1536544616811"></p>
<p><strong>逻辑回归的损失函数</strong>：</p>
<p>逻辑回归采用交叉熵作为代价函数，即对数损失函数。能够有效避免梯度消失.</p>
<p>对数损失函数（logarithmic loss function) 或对数似然损失函数(log-likehood loss function)：</p>
<p>$$L(Y,P(Y|X))=−logP(Y|X)$$</p>
<p>逻辑回归中，采用的是负对数损失函数。如果损失函数越小，表示模型越好。</p>
<p><strong>极大似然估计</strong>：</p>
<p>极大似然原理的直观想法是，一个随机试验如有若干个可能的结果A，B，C，… ，若在一次试验中，结果A出现了，那么可以认为实验条件对A的出现有利，也即出现的概率P(A)较大。一般说来，事件A发生的概率与某一未知参数θ有关，  θ取值不同，则事件A发生的概率也不同，当我们在一次试验中事件A发生了，则认为此时的θ值应是一切可能取值中使P(A|θ）达到最大的那一个，极大似然估计法就是要选取这样的θ值作为参数的估计值，使所选取的样本在被选的总体中出现的可能性为最大。</p>
<p>在逻辑回归中目标函数均为最大化条件概率p(y|x),其中x是输入样本</p>
<p>似然：选择参数使似然概率p(y|x,)最大，y是实际标签</p>
<p>过程：目标函数→单个样本的似然概率→所有样本的似然概率→log变换, 将累乘变成累加→负号, 变成损失函数</p>
<p>选择一组参数使得实验结果具有最大概率。</p>
<p><strong>损失函数的由来</strong>：</p>
<p>已知估计函数为：</p>
<p><img src="/../typora-images/clip_image002-1536635833127.png" alt="img"></p>
<p>则似然概率分布为（即输出值为判断为1的概率，但在输出标签值时实际只与0.5作比较）：</p>
<p><img src="/../typora-images/clip_image001-1536636102482.png" alt="img"><br>可以写成概率一般式：</p>
<p><img src="/../typora-images/1536636241454.png" alt="1536636241454"></p>
<p>由最大似然估计原理，我们可以通过m个训练样本值，来估计出值，使得似然函数值（所有样本的似然函数之积）最大</p>
<p><img src="/../typora-images/clip_image001-1536636266192.png" alt="img"><br>求log:</p>
<p><img src="/../typora-images/clip_image001-1536636284902.png" alt="img"><br>取负数，得损失函数：</p>
<p><img src="/../typora-images/clip_image001-1536636334973.png" alt="img"></p>
<p>逻辑回归参数迭代，利用反向传播进行计算：</p>
<p><img src="/../typora-images/1536636433963.png" alt="1536636433963"></p>
<p>上面这个过程计算的是单个样本对wj的梯度更新。</p>
<h2 id="为什么逻辑回归采用似然函数，而不是平方损失函数？"><a href="#为什么逻辑回归采用似然函数，而不是平方损失函数？" class="headerlink" title="为什么逻辑回归采用似然函数，而不是平方损失函数？"></a>为什么逻辑回归采用似然函数，而不是平方损失函数？</h2><p>可以从两个角度理解。</p>
<ol>
<li><p>交叉熵损失函数的好处是可以克服方差代价函数更新权重过慢的问题（针对激活函数是sigmoid的情况）。</p>
<p>原因是其梯度里面不在包含对sigmoid函数的导数：</p>
<p><img src="/../typora-images/clip_image001-1536657627421.png" alt="img"></p>
<p>而如果使用的是平方损失函数加sigmoid函数，则计算梯度时：</p>
<p><img src="/../typora-images/clip_image002-1536657627421.png" alt="img"></p>
<p><img src="/../typora-images/clip_image003-1536657627421.png" alt="img"></p>
<p>会包含sigmoid的导数(sigmoid的导数值始终小于1），使梯度下降变慢。</p>
</li>
<li><p><img src="/../typora-images/1536657740524.png" alt="1536657740524"></p>
</li>
</ol>
<p><img src="/../typora-images/clip_image001.png" alt="img"></p>
<p>图1 最小二乘作为逻辑回归模型的损失函数(非凸），theta为待优化参数</p>
<p>​  </p>
<p><img src="/../typora-images/clip_image001-1536544424958.png" alt="img"></p>
<p>图2 最大似然作为逻辑回归模型的损失函数，theta为待优化参数</p>
<h2 id="逻辑回归为什么使用sigmoid函数"><a href="#逻辑回归为什么使用sigmoid函数" class="headerlink" title="逻辑回归为什么使用sigmoid函数"></a>逻辑回归为什么使用sigmoid函数</h2><p>也可以从两点来进行理解</p>
<ol>
<li><p>Sigmoid 函数自身的性质</p>
<p>因为这是一个最简单的，可导的，0-1阶跃函数</p>
<p>sigmoid 函数连续，单调递增</p>
<p>sigmiod 函数关于（0，0.5） 中心对称</p>
<p>对sigmoid函数求导简单 </p>
</li>
<li><ol>
<li>逻辑回归函数的定义</li>
</ol>
<p><img src="/../typora-images/clip_image001-1536658028024.png" alt="img"></p>
<p>因此, 逻辑回归返回的概率是指判别为1类的概率.</p>
</li>
</ol>
<h2 id="逻辑回归和SVM的异同点"><a href="#逻辑回归和SVM的异同点" class="headerlink" title="逻辑回归和SVM的异同点"></a>逻辑回归和SVM的异同点</h2><p><strong>相同点</strong>：</p>
<p>第一，LR和SVM都是分类算法。</p>
<p>第二，如果不考虑核函数，LR和SVM都是线性分类算法，也就是说他们的分类决策面都是线性的。</p>
<p>第三，LR和SVM都是监督学习算法。</p>
<p>第四，LR和SVM都是判别模型。</p>
<p>判别模型会生成一个表示P(Y|X)的判别函数（或预测模型），而生成模型先计算联合概率p(Y,X)然后通过贝叶斯公式转化为条件概率。简单来说，在计算判别模型时，不会计算联合概率，而在计算生成模型时，必须先计算联合概率。</p>
<p><strong>不同点</strong>：</p>
<p>第一，本质上是其loss function不同</p>
<p>逻辑回归的损失函数是交叉熵函数：</p>
<p><img src="/../typora-images/clip_image001-1536658067618.png" alt="img"></p>
<p>SVM的损失函数：</p>
<p><img src="/../typora-images/clip_image002-1536658067618.png" alt="img"></p>
<p>逻辑回归方法基于概率理论，假设样本为1的概率可以用sigmoid函数来表示，然后通过极大似然估计的方法估计出参数的值；</p>
<p>支持向量机基于几何间隔最大化原理，认为存在最大几何间隔的分类面为最优分类面；</p>
<p>第二，支持向量机只考虑局部的边界线附近的点，而逻辑回归考虑全局（远离的点对边界线的确定也起作用）。</p>
<p>第三，在解决非线性问题时，支持向量机采用核函数的机制，而LR通常不采用核函数的方法。</p>
<p>这个问题理解起来非常简单。分类模型的结果就是计算决策面，模型训练的过程就是决策面的计算过程。通过上面的第二点不同点可以了解，在计算决策面时，SVM算法里只有少数几个代表支持向量的样本参与了计算，也就是只有少数几个样本需要参与核计算（即kernal machine解的系数是稀疏的）。然而，LR算法里，每个样本点都必须参与决策面的计算过程，也就是说，假设我们在LR里也运用核函数的原理，那么每个样本点都必须参与核计算，这带来的计算复杂度是相当高的。所以，在具体应用时，LR很少运用核函数机制。</p>
<p>第四，SVM的损失函数就自带正则</p>
<p>参考：</p>
<p>Poll的博客：<a href="http://www.cnblogs.com/maybe2030/p/5494931.html" target="_blank" rel="noopener">www.cnblogs.com/maybe2030/p/5494931.html</a></p>
<p>逻辑回归：<a href="https://www.cnblogs.com/Belter/p/6128644.html" target="_blank" rel="noopener">https://www.cnblogs.com/Belter/p/6128644.html</a></p>
<p>逻辑回归推导：<a href="http://blog.csdn.net/pakko/article/details/37878837" target="_blank" rel="noopener">http://blog.csdn.net/pakko/article/details/37878837</a></p>
<p>极大似然估计：<a href="http://blog.csdn.net/star_liux/article/details/39666737" target="_blank" rel="noopener">http://blog.csdn.net/star_liux/article/details/39666737</a></p>
<p>刘建平：<a href="https://www.cnblogs.com/pinard/p/6035872.html" target="_blank" rel="noopener">https://www.cnblogs.com/pinard/p/6035872.html</a></p>
<p>逻辑回归和SVM的比较：<a href="https://www.cnblogs.com/zhizhan/p/5038747.html" target="_blank" rel="noopener">https://www.cnblogs.com/zhizhan/p/5038747.html</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="hellodavid.top/2018/09/11/L1 and L2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="David">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/myavatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HelloDavid">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/11/L1 and L2/" itemprop="url">L1和L2正则化</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-09-11T17:56:10+08:00">
                2018-09-11
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="L0范数，L1范数，L2范数"><a href="#L0范数，L1范数，L2范数" class="headerlink" title="L0范数，L1范数，L2范数"></a>L0范数，L1范数，L2范数</h1><p><strong>L0范数</strong>是指向量中非0元素的个数。</p>
<p>如果我们用L0范数来规则化一个参数矩阵W的话（正则项），就是希望W的大部分元素都是0。换句话说，让参数W是稀疏的。</p>
<p><strong>L1范数</strong>是指向量中各个元素绝对值之和，也有个美称叫“稀疏规则算子”（Lasso regularization）。</p>
<h2 id="为什么要稀疏？"><a href="#为什么要稀疏？" class="headerlink" title="为什么要稀疏？"></a>为什么要稀疏？</h2><p>特征选择(Feature Selection)：</p>
<p>稀疏规则化它能实现特征的自动选择。一般来说，一个样本的大部分特征都是和最终的输出没有关系或者不提供任何信息的，在最小化目标函数的时候考虑这些额外的特征，虽然可以获得更小的训练误差，但在预测新的样本时，这些没用的信息被考虑反而干扰了对正确标签的预测。稀疏规则化算子的引入就是为了完成特征自动选择的光荣使命，它会学习地去掉这些没有信息的特征，也就是把这些特征对应的权重置为0。</p>
<p>可解释性(Interpretability)：</p>
<p>另一个青睐于稀疏的理由是，模型更容易解释。例如患某种病的概率是y，然后我们收集到的数据x是1000维的，也就是我们需要寻找这1000种因素到底是怎么影响患上这种病的概率的。假设我们这个是个回归模型：$y=w_1x_1+w_2x_2+…+w_1000x_1000+b$ (为了让y限定在[0,1]的范围，一般还得加个Logistic函数）。通过学习，如果最后学习到的w就只有很少的非零元素，例如只有5个非零的$w_i$，那么我们就有理由相信，这些对应的特征在患病分析上面提供的信息是巨大的，决策性的。也就是说，患不患这种病只和这5个因素有关，那医生就好分析多了。但如果1000个$w_i$都非0，医生面对这1000种因素，累觉不爱。</p>
<p><strong>L2范数</strong>是指向量各元素的平方和然后求平方根。作用是改善过拟合。</p>
<p>在回归里面，有人把有它的回归叫“岭回归”（Ridge Regression），有人也叫它“权值衰减weight decay”。 </p>
<p>实际上，对于L1和L2规则化的代价函数来说，我们可以写成以下形式：</p>
<p><img src="/../typora-images/clip_image001-1536658592630.png" alt="img"></p>
<h1 id="为什么L1正则化可以取稀疏解"><a href="#为什么L1正则化可以取稀疏解" class="headerlink" title="为什么L1正则化可以取稀疏解"></a>为什么L1正则化可以取稀疏解</h1><p>等值线图的理解：</p>
<p><img src="/../typora-images/clip_image001-1536475369274.png" alt="l1l2"></p>
<p>目标函数由两部分组成：原始的损失函数和正则项</p>
<p><img src="/../typora-images/clip_image001-1536475441887.png" alt="img"></p>
<p>其中$J_0$是原始的损失函数，是关于权重w的函数，上图中的等值线图考虑了只有两个权重系数的情况。</p>
<p>右上方的彩色圆圈是关于原始损失函数的等值线图，可以想象成是一个曲面压平后的结果。</p>
<p>因此，每一圈上的每个坐标带入原始损失函数得到的损失值是相同的。</p>
<p>由于原始损失函数是凸函数，因此紫色中心是取值最小的，也就是说，不加正则项，我们应该取紫色点的权重坐标。而越往外扩散，原始损失函数的取值越大。</p>
<p>注意：等值线图并没有画全，还可以继续向外扩散。</p>
<p>正则项相当于对原始损失函数做了约束，令L代表正则项，因此黑色线圈表示满足约束的权重坐标。</p>
<p>如果是L1， 则$L=|w_1| + |w_2|$， 若为L2， 则$L = |w_1|^2 + |w_2|^2$</p>
<p>因此，为了要满足约束，我们要取黑色线与彩色线的交点，但是同时为了使彩色线的取值尽可能小，我们需要取尽可能靠近紫色线方向的线圈，因此最终取图中的交点。否则，如果和黑色线上别的交点相交，彩色线圈会往外移，导致取值增加。</p>
<h1 id="为什么L2可以获得平滑的解？-从理论角度"><a href="#为什么L2可以获得平滑的解？-从理论角度" class="headerlink" title="为什么L2可以获得平滑的解？(从理论角度)"></a>为什么L2可以获得平滑的解？(从理论角度)</h1><p>假设原始损失函数为：</p>
<p><img src="/../typora-images/clip_image001-1536658624997.png" alt="2m "></p>
<p>此时，进行梯度迭代的公式为：</p>
<p><img src="/../typora-images/clip_image001-1536658638373.png" alt="img"></p>
<p>如果加上L2正则项，则梯度更新公式变为：</p>
<p><img src="/../typora-images/clip_image001-1536658650941.png" alt="img"></p>
<p>因此，与未添加L2的情况相比，参数每次迭代都要乘以一个小于1的因子，从而使得参数不断减小。 </p>
<h1 id="为什么正则化-参数较小可以防止过拟合？"><a href="#为什么正则化-参数较小可以防止过拟合？" class="headerlink" title="为什么正则化/参数较小可以防止过拟合？"></a>为什么正则化/参数较小可以防止过拟合？</h1><ol>
<li>直观理解就是：正则项λ越大，那么权重就会越小，使得神经网络变得简单。</li>
</ol>
<p>根据激活函数理解，假设激活函数是tanh:</p>
<p><img src="/../typora-images/clip_image001-1536475970668.png" alt="img"></p>
<p>可以发现，当z值较小时，激活函数的部分几乎为线性形状。</p>
<p>如果正则化项λ很大，那么权重就会很小，因此相对来说，z=wx+b也会很小，因此在这段范围内，激活函数呈线性，和线性回归类似，因此，当每层网络都是线性网络，那么整个网络都是一个线性网络，无法适用于复杂决策，不会发生过拟合。</p>
<ol start="2">
<li>过拟合的时候，拟合函数的系数往往非常大，为什么？如下图所示，过拟合，就是拟合函数需要顾忌每一个点，最终形成的拟合函数波动很大。在某些很小的区间里，函数值的变化很剧烈。这就意味着函数在某些小区间里的导数值（绝对值）非常大，由于自变量值可大可小，所以只有系数足够大，才能保证导数值很大。</li>
</ol>
<p><img src="/../typora-images/clip_image002-1536475970668.png" alt="img"></p>
<p>而正则化是通过约束参数的范数使其不要太大，所以可以在一定程度上减少过拟合情况。</p>
<p>贝叶斯派解释：</p>
<p>加2范数正则等价于加了高斯分布的先验，加1范数正则相当于加拉普拉斯分布先验。</p>
<h1 id="为什么L2得到的系数趋于相同"><a href="#为什么L2得到的系数趋于相同" class="headerlink" title="为什么L2得到的系数趋于相同"></a>为什么L2得到的系数趋于相同</h1><p>L2正则化将系数向量的L2范数添加到了损失函数中。由于L2惩罚项中系数是二次方的，这使得L2和L1有着诸多差异，最明显的一点就是，L2正则化会让系数的取值变得平均。对于关联特征，这意味着他们能够获得更相近的对应系数。还是以Y=X1+X2为例，假设X1和X2具有很强的关联，如果用L1正则化，不论学到的模型是Y=X1+X2还是Y=2X1，惩罚都是一样的，都是2alpha。但是对于L2来说，第一个模型的惩罚项是2alpha，但第二个模型的是4*alpha。可以看出，系数之和为常数时，各系数相等时惩罚是最小的，所以才有了L2会让各个系数趋于相同的特点。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>因此，一句话总结就是：L1会趋向于产生少量的特征，而其他的特征都是0，而L2会选择更多的特征，这些特征都会接近于0。Lasso在特征选择时候非常有用，而Ridge就只是一种规则化而已。</p>
<p>L1正则假设参数的先验分布是Laplace分布，可以保证模型的稀疏性，也就是某些参数等于0；</p>
<p>L2正则假设参数的先验分布是Gaussian分布，可以保证模型的稳定性，也就是参数的值不会太大或太小；</p>
<p>在实际使用中，如果特征是高维稀疏的，则使用L1正则；如果特征是低维稠密的，则使用L2正则。</p>
<p>参考：</p>
<p>百度知道：<a href="https://zhidao.baidu.com/question/1864240911512690707.html" target="_blank" rel="noopener">https://zhidao.baidu.com/question/1864240911512690707.html</a></p>
<p>博客：<a href="http://blog.csdn.net/zouxy09/article/details/24971995" target="_blank" rel="noopener">http://blog.csdn.net/zouxy09/article/details/24971995</a></p>
<p>L2正则化导致参数较小：<a href="https://blog.csdn.net/jinping_shi/article/details/52433975" target="_blank" rel="noopener">https://blog.csdn.net/jinping_shi/article/details/52433975</a></p>
<p>等值线图形的解释：<a href="https://blog.csdn.net/weixin_39845112/article/details/80114918" target="_blank" rel="noopener">https://blog.csdn.net/weixin_39845112/article/details/80114918</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="hellodavid.top/2018/09/11/FM & FFM/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="David">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/myavatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HelloDavid">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/11/FM & FFM/" itemprop="url">因子分解机 FM和FFM</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-09-11T17:56:10+08:00">
                2018-09-11
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/推荐系统/" itemprop="url" rel="index">
                    <span itemprop="name">推荐系统</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="因子分解机-Factorization-Machine"><a href="#因子分解机-Factorization-Machine" class="headerlink" title="因子分解机 Factorization Machine"></a>因子分解机 Factorization Machine</h1><p>因子分解机主要是考虑了特征之间的关联。</p>
<p>FM主要是为了解决数据稀疏的情况下，（而SVM无法解决稀疏问题），特征怎样组合的问题。</p>
<p><strong>数据稀疏</strong>是指数据的维度很大，但是其中为0的维度很多。推荐系统是常见应用场景，原因是推荐系统中类别属性（如商品id）比较多，每一种类别属性经过onehot处理后会产生大量值为0的特征，导致样本变得稀疏，而FM就可以解决这种样本稀疏的问题。</p>
<p>因子分解机FM算法可以处理如下三类问题：</p>
<p><img src="/../typora-images/clip_image001-1536584997387.png" alt=""></p>
<h2 id="普通线性模型"><a href="#普通线性模型" class="headerlink" title="普通线性模型"></a>普通线性模型</h2><p>我们将各个特征独立考虑，并没有考虑特征之间的相互关系。</p>
<p><img src="/../typora-images/clip_image001-1536585226605.png" alt="img"></p>
<h2 id="FM模型"><a href="#FM模型" class="headerlink" title="FM模型"></a>FM模型</h2><p>为了表述特征间的相关性，我们采用多项式模型，将特征$x_i$和$x_j$的组合用$x_ix_j$表示，只讨论二阶多项式模型：</p>
<p><img src="/../typora-images/clip_image001-1536589643887.png" alt="j=i+1 "></p>
<p>其中，n表示样本的维度（是已经进行onehot以后的特征数量），$x_i$表示第i个特征，(如果是类别变量，那么onehot后只有一个维度值为1，其余维度值为0，因此在这种情况下$x_i$的值通常是取0和1，而对于一般的数值维度，$x_i$的值对应原来的数值)， $w_{ij}$是组合参数，代表组合特征的重要性，注意：$w_{ij}$和$w_{ji}$是相等的，因此组合特征部分相关参数共有$(n-1)+(n-2)+…+1=n(n-1)/2$</p>
<p>注意到，在数据稀疏的情况下，满足特征$x_i$和$x_j$都不为0的情况很少，因此$w_{ij}$很难训练。</p>
<p>为了求解组合参数$w_{ij}$, 对每个特征分量$x_i$引入k维（k远小于n) 的辅助向量$v_i=(v_{i1}, v_{i2},…,v_{ik})$, 然后利用向量内积的结果$v_iv_j^T$来表示原来的组合参数$w_{ij}$</p>
<p><img src="/../typora-images/clip_image001-1536631892999.png" alt=" "></p>
<p>实际上，辅助向量可以理解为是特征分量的另一种表示形式，类似于词向量的表示形式，但是和词向量存在区别。词向量中是将一个单词转换为向量表示形式，而单词是固定的，因此一个单词对应一个词向量；而在FM中，我们是将一个类别特征（注意，这是onehot前的特征）转换为一个向量，但由于该类别特征可以有多种取值，并且每种取值对应一个向量(也就是上面将类别特征onehot以后，每个特征分量对应一个辅助向量），因此，FM中确实是将一个类别特征转换为了向量形式，只不过向量会根据特征的取值发生变化。</p>
<p>此时，组合参数$w_{ij}$组成的矩阵可以表示为：</p>
<p><img src="/../typora-images/clip_image001-1536632613894.png" alt="= vvT "></p>
<p><strong>将组合参数进行分解的好处</strong>：</p>
<ol>
<li>从原来要求n(n-1)/2个组合参数变成了求矩阵V，参数数量变为n*k. </li>
<li>削弱了高阶参数间的独立性：k越大（即对特征分量的表征能力越强），高阶参数间独立性越强，模型越精细；k越小，泛化能力越强，</li>
</ol>
<p>因此实际问题选择较小的k可以克服稀疏数据的问题，并获得较好的预测效果。</p>
<p>因此时间复杂度从O(n^2)变成了O(kn)</p>
<p>此时，<strong>分解机的表示形式变为</strong>：</p>
<p><img src="/../typora-images/clip_image001-1536632765164.png" alt="img"></p>
<p>注意第二项，下标j的循环从i+1开始。</p>
<p><strong>使用辅助向量乘积表示组合参数的原理</strong>：</p>
<p>通常，由于数据稀疏，本来组合参数是学习不到的，但是我们可以通过特征i与其他特征的数据的关系，特征j和其他特征的关系，分别学习到特征i和特征j的对应的辅助向量$v_i$和$v_j$,这样利用$v_iv_j^T$来表示$w_{ij}$，便可以解决数据稀疏带来的问题。</p>
<p><strong>计算模型的预测值</strong>：</p>
<p>在计算模型时，只需要考虑计算量最大的二次项：</p>
<p><img src="/../typora-images/clip_image001-1536632968293-1536632969546.png" alt="img"></p>
<p>可以先把<strong>标量</strong>$x_i$和对应的辅助向量$v_i$相乘，并记录下来，得到$u_i=x_iv_i$, 注意$x_i$只是标量。</p>
<p>对于n个元素，共需要n*k次乘法，于是二元项变为：注意：<strong>公式中的r即为k</strong>,即辅助向量的维度</p>
<p><img src="/../typora-images/clip_image001-1536633106003.png" alt="img"></p>
<p><img src="/../typora-images/clip_image002.png" alt="img"></p>
<p>把上式凑成和的平方：</p>
<p><img src="/../typora-images/clip_image003.png" alt="img"></p>
<p>化简的原理是将整个对称矩阵W除去对角线上的数值，由于对称，再除以2得到原来的上三角矩阵。</p>
<p>括号内，两部分计算量均为O(n),因此整体计算量为O(kn)。</p>
<p><strong>梯度下降求解模型参数</strong>：</p>
<p>SGD中，需要计算两种导数：</p>
<ol>
<li>预测值对一元参数的导数：</li>
</ol>
<p><img src="/../typora-images/clip_image001-1536633238298.png" alt="img"></p>
<ol>
<li>预测值对二元参数的导数：</li>
</ol>
<p><img src="/../typora-images/clip_image002-1536633238298.png" alt="img"></p>
<p><strong>实际处理问题</strong>：</p>
<p>回归问题：</p>
<p>在回归问题中，直接使用模型预测值作为预测结果，并使用最小均方误差作为损失函数，其中m为样本个数：</p>
<p><img src="/../typora-images/clip_image003-1536633238298.png" alt="img"></p>
<p>二分类问题：</p>
<p>将输出结果通过激活函数，如sigmoid函数得到预测类别的概率，使用对数似然作为损失函数：</p>
<p><img src="/../typora-images/clip_image004.png" alt="img"></p>
<h1 id="场感知分解机-FFM"><a href="#场感知分解机-FFM" class="headerlink" title="场感知分解机 FFM"></a>场感知分解机 FFM</h1><p>FM的应用场景：给定一组数据，判定用户是否会进行点击。</p>
<p>采用onehot对categorical类型的数据进行编码后，数据会十分稀疏，并且数据维度增大。</p>
<p>以广告分类为例，“Day=26/11/15”、“Day=1/7/14”、“Day=19/2/15”这三个特征都是代表日期的，可以放到同一个field中。同理，商品的末级品类编码生成了550个特征，这550个特征都是说明商品所属的品类，因此它们也可以放到同一个field中。简单来说，同一个categorical特征经过One-Hot编码生成的数值特征都可以放到同一个field，包括用户性别、职业、品类偏好等。</p>
<h2 id="Field-aware-Factorization-Machine-FFM-模型"><a href="#Field-aware-Factorization-Machine-FFM-模型" class="headerlink" title="Field-aware Factorization Machine(FFM) 模型"></a>Field-aware Factorization Machine(FFM) 模型</h2><p>场感知说白了可以理解引入了field的概念，FFM把相同性质的特征归于同一个field。</p>
<p>因此，隐向量不仅与特征相关，也与filed相关，</p>
<p>即：对每一维特征分量$x_i$, 针对每一种field $f_j$ , 都会学习一个隐向量$v_{i, f_j}$，与不同的特征关联需要使用不同的隐向量 (而FM每种特征只有一个隐向量)<br>例如，当考虑“Day=26/11/15”这个特征，与“Country”特征和“Ad_type”特征进行关联的时候，需要使用不同的隐向量，而在FM中则使用相同的隐向量。</p>
<p> 假设样本的n个特征（已经onehot)属于f个field, 那么FFM二次项有nf个隐向量。</p>
<p>因此，得到：</p>
<p><img src="/../typora-images/clip_image002-1536633337692.png" alt="img"></p>
<p>其中，$f_j$是第j个特征所属的field. 如果隐向量的长度为k, 那么FFM的交叉项参数就有nfk个，远多于FM模型的nk个。此外，由于隐向量于filed有关，FFM的交叉项并不能够像FM那样进行化简，预测复杂度为$O(kn^2)$. </p>
<p>FFM的使用：所有的特征必须转换成“field_id:feat_id:value”格式，field_id代表特征所属field的编号，feat_id是特征编号，value是特征的值. </p>
<p>在FFM论文版本里的梯度更新，学习率是通过类似于adagrad自适应的学习率计算的。根据AdaGrad的特点，对于样本比较稀疏的特征，学习率高于样本比较密集的特征，因此每个参数既可以比较快速达到最优，也不会导致验证误差出现很大的震荡。</p>
<p>参考：</p>
<p>FM算法详解：<a href="https://blog.csdn.net/bitcarmanlee/article/details/52143909" target="_blank" rel="noopener">https://blog.csdn.net/bitcarmanlee/article/details/52143909</a></p>
<p>FM计算：<a href="https://blog.csdn.net/shenxiaolu1984/article/details/78740481" target="_blank" rel="noopener">https://blog.csdn.net/shenxiaolu1984/article/details/78740481</a></p>
<p>fm美团：<a href="https://tech.meituan.com/deep_understanding_of_ffm_principles_and_practices.html" target="_blank" rel="noopener">https://tech.meituan.com/deep_understanding_of_ffm_principles_and_practices.html</a></p>
<p>csdn， 推荐算法：<a href="https://blog.csdn.net/asd136912/article/details/78318563" target="_blank" rel="noopener">https://blog.csdn.net/asd136912/article/details/78318563</a></p>
<p>美团，FFM: <a href="https://tech.meituan.com/deep_understanding_of_ffm_principles_and_practices.html" target="_blank" rel="noopener">https://tech.meituan.com/deep_understanding_of_ffm_principles_and_practices.html</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="hellodavid.top/2018/08/26/Leetcode-Reverse Linked List/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="David">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/myavatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HelloDavid">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/26/Leetcode-Reverse Linked List/" itemprop="url">Remove Duplicates from Sorted List</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-26T17:40:32+08:00">
                2018-08-26
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Python/" itemprop="url" rel="index">
                    <span itemprop="name">Python</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>从排序链表中删除重复元素。<br><a href="https://leetcode.com/problems/remove-duplicates-from-sorted-list/description/" target="_blank" rel="noopener">Description</a></p>
<p><strong>解题思路</strong>：<br>依次比较相邻的两个链表元素，若值相等，则将前一个节点的next引用为后一个节点的后一个节点。使用cur来依次向下遍历元素，最后返回head。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"># class ListNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.next = None</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">deleteDuplicates</span><span class="params">(self, head)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type head: ListNode</span></span><br><span class="line"><span class="string">        :rtype: ListNode</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        cur = head</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">while</span> cur:</span><br><span class="line">            <span class="keyword">while</span> cur.next <span class="keyword">and</span> cur.next.val==cur.val:</span><br><span class="line">                cur.next = cur.next.next</span><br><span class="line">            cur = cur.next</span><br><span class="line">        <span class="keyword">return</span> head</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="hellodavid.top/2018/08/26/machine-learning/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="David">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/myavatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HelloDavid">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/26/machine-learning/" itemprop="url">Machine learning</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-26T14:43:27+08:00">
                2018-08-26
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <blockquote>
<p>本文仅为个人笔记，错误之处敬请包涵。                                                         —— David</p>
<p>这篇介绍不涉及任何公式推导，仅提供一些思路以及相应的资料，感兴趣的可以自行查找资料学习。</p>
</blockquote>
<h2 id="书籍推荐"><a href="#书籍推荐" class="headerlink" title="书籍推荐"></a>书籍推荐</h2><p>理论类：</p>
<p>机器学习，周志华；</p>
<p>统计学习方法，李航；</p>
<p>深度学习，Ian goodfellow;</p>
<p>实践类：</p>
<p>机器学习实战，peter harrington；</p>
<p>python机器学习及实践，范淼；</p>
<p>休闲类：</p>
<p>数学之美，吴军；</p>
<p>##博客推荐：</p>
<p>刘建平的博客：<a href="https://www.cnblogs.com/pinard/" target="_blank" rel="noopener">https://www.cnblogs.com/pinard/</a></p>
<p>peghoty的博客：<a href="https://blog.csdn.net/itplus" target="_blank" rel="noopener">https://blog.csdn.net/itplus</a></p>
<p>poll的笔记：<a href="http://www.cnblogs.com/maybe2030/" target="_blank" rel="noopener">http://www.cnblogs.com/maybe2030/</a></p>
<h2 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h2><p>监督学习是指对<strong>带标签</strong>的数据进行模型学习。</p>
<h3 id="回归"><a href="#回归" class="headerlink" title="回归"></a>回归</h3><p>回归任务常见的是线性回归linear regression. </p>
<p>注意回归和分类任务的区别，回归的标签值是连续值，而分类的标签值是离散值。</p>
<p>通常我们还会遇到逻辑回归logistic regression, 注意，逻辑回归是用于分类的！</p>
<p>逻辑回归LR是机器学习中非常基础的算法，因此非常重要。</p>
<p>知识点：交叉熵损失函数，极大似然估计。</p>
<p>相关资料：</p>
<p>poll的博客：<a href="http://www.cnblogs.com/maybe2030/p/5494931.html" target="_blank" rel="noopener">www.cnblogs.com/maybe2030/p/5494931.html</a> </p>
<p>逻辑回归：<a href="https://www.cnblogs.com/Belter/p/6128644.html" target="_blank" rel="noopener">https://www.cnblogs.com/Belter/p/6128644.html</a></p>
<p>逻辑回归推导：<a href="http://blog.csdn.net/pakko/article/details/37878837" target="_blank" rel="noopener">http://blog.csdn.net/pakko/article/details/37878837</a></p>
<p>极大似然估计：<a href="http://blog.csdn.net/star_liux/article/details/39666737" target="_blank" rel="noopener">http://blog.csdn.net/star_liux/article/details/39666737</a></p>
<h3 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h3><p>通俗来讲，它是一种二类分类模型，其基本模型定义为特征空间上的间隔最大的线性分类器，其学习策略便是间隔最大化，最终可转化为一个凸二次规划问题的求解。</p>
<p>知识点：函数间隔，几何间隔，对偶问题，核函数，软间隔，hinge loss</p>
<p>相关资料：</p>
<p>周志华，机器学习：SVM</p>
<p>图形解释，知乎：<a href="https://www.zhihu.com/question/21094489" target="_blank" rel="noopener">https://www.zhihu.com/question/21094489</a></p>
<p>支持向量机通俗解释，CSDN: <a href="http://blog.csdn.net/v_july_v/article/details/7624837" target="_blank" rel="noopener">http://blog.csdn.net/v_july_v/article/details/7624837</a></p>
<p>支持向量机通俗导论，july: <a href="https://blog.csdn.net/v_july_v/article/details/7624837" target="_blank" rel="noopener">https://blog.csdn.net/v_july_v/article/details/7624837</a></p>
<h3 id="KNN"><a href="#KNN" class="headerlink" title="KNN"></a>KNN</h3><p>给定测试样本，基于某种距离度量找出训练集中与其最靠近的k个训练样本，然后基于这k个邻居的信息来进行预测。K=1时，为最近邻算法。 </p>
<p>知识点：k值的选择，距离度量，kd树定义及构建</p>
<p>相关资料：</p>
<p>李航，统计学习，第三章 </p>
<h3 id="因子分解机"><a href="#因子分解机" class="headerlink" title="因子分解机"></a>因子分解机</h3><p>因子分解机主要是考虑了特征之间的关联。</p>
<p>FM主要是为了解决数据稀疏的情况下，（而SVM无法解决稀疏问题），特征怎样组合的问题。</p>
<p>知识点：计算复杂度的推导，梯度计算</p>
<p>相关资料：</p>
<p>FM算法详解：<a href="https://blog.csdn.net/bitcarmanlee/article/details/52143909" target="_blank" rel="noopener">https://blog.csdn.net/bitcarmanlee/article/details/52143909</a></p>
<p>FM计算：<a href="https://blog.csdn.net/shenxiaolu1984/article/details/78740481" target="_blank" rel="noopener">https://blog.csdn.net/shenxiaolu1984/article/details/78740481</a></p>
<p>###HMM隐马尔可夫模型</p>
<p>隐马模型相对包含内容较多，需要考虑三个基本问题：评估问题，解码问题，和学习问题。</p>
<p>为了更好的理解隐马模型，可以通过<a href="http://www.cnblogs.com/skyme/p/4651331.html" target="_blank" rel="noopener">http://www.cnblogs.com/skyme/p/4651331.html</a> 这篇文章入门，对隐马模型的隐含状态，可见状态，转换概率等概念有较为清楚的理解。</p>
<p>知识点：评估问题，前向后向算法；解码问题，维特比算法；学习问题，EM算法</p>
<p>相关资料：</p>
<p>Cnblog，骰子说明隐马模型：<a href="http://www.cnblogs.com/skyme/p/4651331.html" target="_blank" rel="noopener">http://www.cnblogs.com/skyme/p/4651331.html</a></p>
<p>维特比算法说明,及python实现：<a href="https://www.cnblogs.com/ylHe/p/6912017.html" target="_blank" rel="noopener">https://www.cnblogs.com/ylHe/p/6912017.html</a></p>
<p>数学之美，第5章，隐马模型，BW算法</p>
<h2 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h2><p>无监督学习是对<strong>无标签</strong>的数据进行模型学习。</p>
<h3 id="聚类"><a href="#聚类" class="headerlink" title="聚类"></a>聚类</h3><p>最基本的算法是K-means, 通过不断的迭代得到最终结果。</p>
<p>知识点：K-means的步骤，k值的确定（注意，这里的k和knn中的k概念不同），如何确定k个初始类簇中心点；</p>
<h3 id="频繁项集和关联分析"><a href="#频繁项集和关联分析" class="headerlink" title="频繁项集和关联分析"></a>频繁项集和关联分析</h3><p>频繁项集主要是指经常出现在一块的物品的集合，关联分析是指从大规模数据中寻找物品间的隐含关系。在寻找频繁项集的过程中，主要有两种算法，Apriori以及FP-growth.</p>
<p>知识点：清楚相关概念：包括项，项集，事务，关联分析，频繁项集，关联规则，支持度，置信度；熟悉Apriori，和FP-growth算法</p>
<p>相关资料：</p>
<p>FP-tree算法的实现：<a href="https://www.cnblogs.com/zhangchaoyang/articles/2198946.html" target="_blank" rel="noopener">https://www.cnblogs.com/zhangchaoyang/articles/2198946.html</a><br>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2018/08/26/machine-learning/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="hellodavid.top/2018/08/26/hello-world/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="David">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/myavatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HelloDavid">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/26/hello-world/" itemprop="url">Hello World</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-26T14:20:08+08:00">
                2018-08-26
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/test/" itemprop="url" rel="index">
                    <span itemprop="name">test</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="hexo-更新"><a href="#hexo-更新" class="headerlink" title="hexo 更新"></a>hexo 更新</h2><p>hexo clean</p>
<p>hexo g -d</p>
<p><img src="/../typora-images/myavatar.jpg" alt="David"> </p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  


          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/myavatar.jpg"
                alt="David" />
            
              <p class="site-author-name" itemprop="name">David</p>
              <p class="site-description motion-element" itemprop="description">From Zero to One</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">6</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">7</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">David</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
